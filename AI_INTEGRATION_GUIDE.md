# ü§ñ T√≠ch H·ª£p AI Model t·ª´ Google Colab

Hi·ªán t·∫°i ChatBot s·ª≠ d·ª•ng **Pattern Matching** (rule-based). ƒê·ªÉ n√¢ng cao ch·∫•t l∆∞·ª£ng, b·∫°n c√≥ th·ªÉ t√≠ch h·ª£p AI model t·ª´ Google Colab ho·∫∑c Hugging Face.

## Ph∆∞∆°ng √°n 1: D√πng Hugging Face Inference API (D·ªÖ nh·∫•t ‚úÖ)

### B∆∞·ªõc 1: T·∫°o t√†i kho·∫£n Hugging Face
- Truy c·∫≠p: https://huggingface.co/join
- ƒêƒÉng k√Ω t√†i kho·∫£n mi·ªÖn ph√≠
- T·∫°o API token: https://huggingface.co/settings/tokens

### B∆∞·ªõc 2: C√†i ƒë·∫∑t dependencies
```bash
cd /workspaces/Duokid/python-service
pip install requests
```

### B∆∞·ªõc 3: S·ª≠a `main.py` ƒë·ªÉ d√πng Hugging Face API

Thay th·∫ø h√†m `chat()` b·∫±ng:

```python
import requests

HF_API_URL = "https://api-inference.huggingface.co/models/microsoft/DialoGPT-small"
HF_API_TOKEN = "YOUR_HUGGING_FACE_API_TOKEN"  # L·∫•y t·ª´ https://huggingface.co/settings/tokens

@app.post("/api/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    """
    AI Chat s·ª≠ d·ª•ng Hugging Face DialoGPT
    """
    message = req.message.strip()
    
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
    
    try:
        response = requests.post(
            HF_API_URL,
            headers=headers,
            json={"inputs": message},
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            # DialoGPT tr·∫£ v·ªÅ d·∫°ng: [{"generated_text": "..."}]
            ai_reply = result[0]["generated_text"] if result else message
            return ChatResponse(reply=ai_reply)
        else:
            return ChatResponse(reply="Sorry, AI service is temporarily unavailable. Please try again.")
    
    except Exception as e:
        print(f"Hugging Face API Error: {e}")
        # Fallback to pattern matching
        return ChatResponse(reply="Let's practice vocabulary or check the examples!")
```

### B∆∞·ªõc 4: Kh·ªüi ƒë·ªông l·∫°i Python service
```bash
pkill -f "python.*main.py"
sleep 2
cd /workspaces/Duokid/python-service && python main.py &
```

---

## Ph∆∞∆°ng √°n 2: Ch·∫°y Model t·ª´ Google Colab (N√¢ng cao)

### B∆∞·ªõc 1: T·∫°o Colab Notebook
1. Truy c·∫≠p: https://colab.research.google.com
2. T·∫°o notebook m·ªõi
3. Paste code d∆∞·ªõi ƒë√¢y:

```python
# Ch·∫°y AI Model t·ª´ Colab
!pip install fastapi uvicorn torch transformers

from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

app = FastAPI()

# Load model (DialoGPT or GPT-2)
tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-small")
model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-small")

class ChatRequest(BaseModel):
    message: str
    context: str = None

@app.post("/api/chat")
async def chat(req: ChatRequest):
    input_ids = tokenizer.encode(req.message + tokenizer.eos_token, return_tensors='pt')
    chat_history_ids = model.generate(input_ids, max_length=100, pad_token_id=tokenizer.eos_token_id)
    reply = tokenizer.decode(chat_history_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)
    return {"reply": reply}

@app.get("/health")
async def health():
    return {"status": "ok"}

if __name__ == "__main__":
    # S·ª≠ d·ª•ng ngrok ho·∫∑c cloudflare tunnel ƒë·ªÉ expose
    !pip install pyngrok
    from pyngrok import ngrok
    
    public_url = ngrok.connect(8000)
    print(f"üåê Public URL: {public_url}")
    
    uvicorn.run(app, host="127.0.0.1", port=8000)
```

### B∆∞·ªõc 2: Expose Colab Server
```python
# T·∫°o tunnel v·ªõi Cloudflare (mi·ªÖn ph√≠, kh√¥ng c·∫ßn API key)
!pip install cloudflare-tunnel
# Ho·∫∑c d√πng ngrok v·ªõi free tier
```

### B∆∞·ªõc 3: S·ª≠a Java Backend
S·ª≠a `ChatBotController.java`:
```java
private final String PYTHON_SERVICE_URL = "YOUR_COLAB_PUBLIC_URL"; // https://xxx.ngrok.io
```

---

## Ph∆∞∆°ng √°n 3: D√πng OpenAI API

### B∆∞·ªõc 1: L·∫•y OpenAI API Key
- T·∫°o t√†i kho·∫£n: https://openai.com/api/
- L·∫•y API key: https://platform.openai.com/api-keys

### B∆∞·ªõc 2: C√†i ƒë·∫∑t
```bash
pip install openai
```

### B∆∞·ªõc 3: S·ª≠a `main.py`

```python
import openai

openai.api_key = "YOUR_OPENAI_API_KEY"

@app.post("/api/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful English learning assistant for Vietnamese students."},
                {"role": "user", "content": req.message}
            ],
            temperature=0.7,
            max_tokens=100
        )
        return ChatResponse(reply=response.choices[0].message.content)
    except Exception as e:
        print(f"OpenAI Error: {e}")
        return ChatResponse(reply="Sorry, AI service is temporarily unavailable.")
```

---

## üöÄ C√°ch kh·ªüi ƒë·ªông nhanh

```bash
# D·ª´ng services c≈©
pkill -f "java.*spring-boot"
pkill -f "python.*main.py"

# Kh·ªüi ƒë·ªông l·∫°i
/workspaces/Duokid/start-services.sh
```

---

## üìä So s√°nh c√°c ph∆∞∆°ng √°n

| Ph∆∞∆°ng √°n | Chi ph√≠ | T·ªëc ƒë·ªô | Ch·∫•t l∆∞·ª£ng | D·ªÖ s·ª≠ d·ª•ng |
|-----------|--------|-------|-----------|-----------|
| Pattern Matching | üÜì | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Hugging Face | üÜì | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Colab + ngrok | üÜì | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| OpenAI API | üí∞ | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

---

## üîç Ki·ªÉm tra k·∫øt n·ªëi

```bash
# Test Java API
curl -X POST http://localhost:8080/chatbot/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"hello"}'

# Test vocabulary
curl -X POST http://localhost:8080/chatbot/api/vocabulary \
  -H "Content-Type: application/json" \
  -d '{"word":"apple"}'
```

**H√£y ch·ªçn ph∆∞∆°ng √°n ph√π h·ª£p v√† cho t√¥i bi·∫øt ƒë·ªÉ t√≠ch h·ª£p!** üéâ
